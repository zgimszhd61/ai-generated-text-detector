{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/vidhikishorwaghela/llm-detect-ai-generated-text?scriptVersionId=187822363\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# AI-Generated Text Detection using BERT\n\nAI-Generated Text Detection project! In this project, I present a robust solution for detecting AI-generated text using BERT, a cutting-edge natural language processing model. Whether you're a researcher, developer, or a curious enthusiast, this project empowers you to explore, understand, and combat AI-generated content effectively.\n\n# BERT, \nAn acronym for Bidirectional Encoder Representations from Transformers, stands as an open-source machine learning framework designed for the realm of natural language processing (NLP). Originating in 2018, this framework was crafted by researchers from Google AI Language. The article aims to explore the architecture, working and applications of BERT.\n\n# What is BERT?\nBERT (Bidirectional Encoder Representations from Transformers) leverages a transformer-based neural network to understand and generate human-like language. BERT employs an encoder-only architecture. In the original Transformer architecture, there are both encoder and decoder modules. The decision to use an encoder-only architecture in BERT suggests a primary emphasis on understanding input sequences rather than generating output sequences.\n\n\n## Table of Contents\n\n- [Introduction](#introduction)\n- [Features](#features)\n- [Getting Started](#getting-started)\n- [Contributing](#contributing)\n- [License](#license)\n\n## Introduction\n\nAI-generated content is becoming increasingly sophisticated, making it challenging to distinguish between genuine and computer-generated text. Our project aims to tackle this issue by leveraging the power of BERT (Bidirectional Encoder Representations from Transformers) to identify and flag AI-generated text segments. Whether you're dealing with chatbots, articles, or social media posts, our solution offers accurate detection, ensuring the authenticity of digital content.\n\n## Features\n\n- **BERT-Powered Detection:** We utilize state-of-the-art BERT models to analyze the semantic context and linguistic nuances, enabling precise identification of AI-generated text.\n- **Effortless Integration:** Seamlessly integrate our solution into your existing applications or workflows, ensuring hassle-free implementation for developers and researchers.\n- **High Accuracy:** Our model is meticulously trained and fine-tuned to achieve high accuracy, minimizing false positives and false negatives for reliable results.\n- **User-Friendly Interface:** With intuitive interfaces and clear instructions, users can easily navigate and utilize the detection tool without any technical expertise.\n\n\n## How It Works\n\nOur solution follows a comprehensive approach to AI-generated text detection:\n\n**Data Preprocessing:** We clean and preprocess the textual data, removing noise and irrelevant information to enhance the accuracy of our model.\n\n**BERT Tokenization:** Leveraging the BERT tokenizer, we encode the preprocessed text, preparing it for input into our detection model.\n\n**Model Training:** Using a BERT-based sequence classification model, we train the system to distinguish between genuine and AI-generated text with a high degree of accuracy.\n\n**Predictions:** Once trained, the model generates predictions for test data, highlighting potential AI-generated content segments.\n\n**Result Analysis:** The results are saved in a CSV file, allowing users to review and analyze the detected segments along with their confidence scores.\n\n## Contributing\n\nWe welcome contributions from the community! Whether you're a seasoned developer, a data science enthusiast, or a domain expert, your insights and expertise can enhance our project. \n\nLooking forward to get connect to some amazing peps out there!üíÉüèª\n","metadata":{}},{"cell_type":"code","source":"# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nfrom nltk.corpus import stopwords\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom transformers import BertTokenizer, BertForSequenceClassification, AdamW\nimport torch\nfrom torch.utils.data import DataLoader, TensorDataset, random_split\n","metadata":{"execution":{"iopub.status.busy":"2023-11-03T07:14:16.632075Z","iopub.execute_input":"2023-11-03T07:14:16.632771Z","iopub.status.idle":"2023-11-03T07:14:39.131486Z","shell.execute_reply.started":"2023-11-03T07:14:16.632734Z","shell.execute_reply":"2023-11-03T07:14:39.130567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the training and testing datasets\ntrain_essays = pd.read_csv(\"/kaggle/input/llm-detect-ai-generated-text/train_essays.csv\")\ntest_essays = pd.read_csv(\"/kaggle/input/llm-detect-ai-generated-text/test_essays.csv\")\n","metadata":{"execution":{"iopub.status.busy":"2023-11-03T07:14:39.133375Z","iopub.execute_input":"2023-11-03T07:14:39.133694Z","iopub.status.idle":"2023-11-03T07:14:39.243035Z","shell.execute_reply.started":"2023-11-03T07:14:39.133666Z","shell.execute_reply":"2023-11-03T07:14:39.242196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Explore the training data\ntrain_essays.info()","metadata":{"execution":{"iopub.status.busy":"2023-11-03T07:14:39.244294Z","iopub.execute_input":"2023-11-03T07:14:39.24461Z","iopub.status.idle":"2023-11-03T07:14:39.289996Z","shell.execute_reply.started":"2023-11-03T07:14:39.244583Z","shell.execute_reply":"2023-11-03T07:14:39.28905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_essays.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-03T07:14:39.291379Z","iopub.execute_input":"2023-11-03T07:14:39.291662Z","iopub.status.idle":"2023-11-03T07:14:39.30842Z","shell.execute_reply.started":"2023-11-03T07:14:39.291637Z","shell.execute_reply":"2023-11-03T07:14:39.307524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check for class balance\nsns.countplot(data=train_essays, x='generated')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-03T07:14:39.311303Z","iopub.execute_input":"2023-11-03T07:14:39.311614Z","iopub.status.idle":"2023-11-03T07:14:39.582052Z","shell.execute_reply.started":"2023-11-03T07:14:39.311589Z","shell.execute_reply":"2023-11-03T07:14:39.580949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Text Preprocessing\nstop_words = set(stopwords.words('english'))\n\ndef clean_text(text):\n    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuations\n    words = text.split()  # Tokenize\n    words = [word.lower() for word in words if word.isalpha()]  # Lowercase and remove non-alphabetic words\n    words = [word for word in words if word not in stop_words]  # Remove stop words\n    return ' '.join(words)\n\ntrain_essays['clean_text'] = train_essays['text'].apply(clean_text)","metadata":{"execution":{"iopub.status.busy":"2023-11-03T07:14:39.58329Z","iopub.execute_input":"2023-11-03T07:14:39.583606Z","iopub.status.idle":"2023-11-03T07:14:40.083101Z","shell.execute_reply.started":"2023-11-03T07:14:39.583577Z","shell.execute_reply":"2023-11-03T07:14:40.082044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split the data into training and validation sets\nX_train, X_val, y_train, y_val = train_test_split(train_essays['clean_text'], train_essays['generated'], test_size=0.2, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-03T07:14:40.084977Z","iopub.execute_input":"2023-11-03T07:14:40.085405Z","iopub.status.idle":"2023-11-03T07:14:40.092651Z","shell.execute_reply.started":"2023-11-03T07:14:40.085371Z","shell.execute_reply":"2023-11-03T07:14:40.0916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tokenization and Encoding for BERT\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True, padding=True, truncation=True, max_length=128)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-03T07:14:40.093831Z","iopub.execute_input":"2023-11-03T07:14:40.094139Z","iopub.status.idle":"2023-11-03T07:14:40.917295Z","shell.execute_reply.started":"2023-11-03T07:14:40.094112Z","shell.execute_reply":"2023-11-03T07:14:40.916492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoded_train = tokenizer(X_train.tolist(), padding=True, truncation=True, return_tensors='pt')\nencoded_val = tokenizer(X_val.tolist(), padding=True, truncation=True, return_tensors='pt')\n","metadata":{"execution":{"iopub.status.busy":"2023-11-03T07:14:40.91867Z","iopub.execute_input":"2023-11-03T07:14:40.918948Z","iopub.status.idle":"2023-11-03T07:15:00.58084Z","shell.execute_reply.started":"2023-11-03T07:14:40.918923Z","shell.execute_reply":"2023-11-03T07:15:00.579879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert labels to tensors\ntrain_labels = torch.tensor(y_train.values)\nval_labels = torch.tensor(y_val.values)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-03T07:15:00.582009Z","iopub.execute_input":"2023-11-03T07:15:00.582315Z","iopub.status.idle":"2023-11-03T07:15:00.608951Z","shell.execute_reply.started":"2023-11-03T07:15:00.582288Z","shell.execute_reply":"2023-11-03T07:15:00.607971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create TensorDatasets\ntrain_dataset = TensorDataset(encoded_train['input_ids'], encoded_train['attention_mask'], train_labels)\nval_dataset = TensorDataset(encoded_val['input_ids'], encoded_val['attention_mask'], val_labels)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-03T07:15:00.610743Z","iopub.execute_input":"2023-11-03T07:15:00.611121Z","iopub.status.idle":"2023-11-03T07:15:00.61616Z","shell.execute_reply.started":"2023-11-03T07:15:00.611087Z","shell.execute_reply":"2023-11-03T07:15:00.615127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# DataLoader for efficient processing\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-03T07:15:00.617431Z","iopub.execute_input":"2023-11-03T07:15:00.617724Z","iopub.status.idle":"2023-11-03T07:15:00.629784Z","shell.execute_reply.started":"2023-11-03T07:15:00.617692Z","shell.execute_reply":"2023-11-03T07:15:00.628994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the BERT model for sequence classification\nmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-11-03T07:15:00.630906Z","iopub.execute_input":"2023-11-03T07:15:00.631235Z","iopub.status.idle":"2023-11-03T07:15:12.290208Z","shell.execute_reply.started":"2023-11-03T07:15:00.6312Z","shell.execute_reply":"2023-11-03T07:15:12.28924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define optimizer and learning rate scheduler\noptimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\nepochs = 10","metadata":{"execution":{"iopub.status.busy":"2023-11-03T07:15:12.293406Z","iopub.execute_input":"2023-11-03T07:15:12.293719Z","iopub.status.idle":"2023-11-03T07:15:12.304608Z","shell.execute_reply.started":"2023-11-03T07:15:12.293692Z","shell.execute_reply":"2023-11-03T07:15:12.303595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training loop\nfor epoch in range(epochs):\n    model.train()\n    total_loss = 0\n\n    for batch in train_loader:\n        input_ids, attention_mask, labels = batch\n        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n\n        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss\n        total_loss += loss.item()\n\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # Gradient clipping to avoid exploding gradients\n        optimizer.step()\n\n    avg_train_loss = total_loss / len(train_loader)\n    print(f\"Epoch {epoch + 1}/{epochs}, Average Training Loss: {avg_train_loss:.2f}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-11-03T07:15:12.305694Z","iopub.execute_input":"2023-11-03T07:15:12.306352Z","iopub.status.idle":"2023-11-03T07:31:37.582938Z","shell.execute_reply.started":"2023-11-03T07:15:12.306314Z","shell.execute_reply":"2023-11-03T07:31:37.581668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Validation loop\nmodel.eval()\nval_preds = []\nval_labels = []\n\nwith torch.no_grad():\n    for batch in val_loader:\n        input_ids, attention_mask, labels = batch\n        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n\n        outputs = model(input_ids, attention_mask=attention_mask)\n        logits = outputs.logits\n\n        val_preds.extend(torch.argmax(logits, dim=1).cpu().numpy())\n        val_labels.extend(labels.cpu().numpy())\n","metadata":{"execution":{"iopub.status.busy":"2023-11-03T07:31:37.584295Z","iopub.execute_input":"2023-11-03T07:31:37.584615Z","iopub.status.idle":"2023-11-03T07:31:46.483805Z","shell.execute_reply.started":"2023-11-03T07:31:37.584587Z","shell.execute_reply":"2023-11-03T07:31:46.482678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate validation accuracy\nval_accuracy = accuracy_score(val_labels, val_preds)\nprint(f\"Validation Accuracy: {val_accuracy:.2f}\")","metadata":{"execution":{"iopub.status.busy":"2023-11-03T07:31:46.486072Z","iopub.execute_input":"2023-11-03T07:31:46.487025Z","iopub.status.idle":"2023-11-03T07:31:46.493984Z","shell.execute_reply.started":"2023-11-03T07:31:46.486983Z","shell.execute_reply":"2023-11-03T07:31:46.492879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test data processing\ntest_inputs = tokenizer(test_essays['text'].tolist(), padding=True, truncation=True, return_tensors='pt')\n\n# Move input tensor to the same device as the model\ntest_inputs = {key: value.to(device) for key, value in test_inputs.items()}\n\n# Generate predictions using your trained model\nwith torch.no_grad():\n    outputs = model(**test_inputs)\n    logits = outputs.logits\n\n# Assuming the first column of logits corresponds to the negative class (non-AI-generated) \n# and the second column corresponds to the positive class (AI-generated)\npredictions = torch.softmax(logits, dim=1)[:, 1].cpu().numpy()  # Move predictions back to CPU\n\n# Create a submission DataFrame with essay IDs and corresponding predictions\nsubmission = pd.DataFrame({\n    'id': test_essays['id'],\n    'generated': predictions\n})\n\n# Save the submission DataFrame to a CSV file\nsubmission.to_csv('/kaggle/working/submission.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-03T07:31:46.495176Z","iopub.execute_input":"2023-11-03T07:31:46.495561Z","iopub.status.idle":"2023-11-03T07:31:46.545354Z","shell.execute_reply.started":"2023-11-03T07:31:46.495523Z","shell.execute_reply":"2023-11-03T07:31:46.544334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
